{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dependencies\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Company Name:Ynot\n"
     ]
    }
   ],
   "source": [
    "# Taking the Input\n",
    "\n",
    "name = input('Enter the Company Name:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guvi Geek Networks Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maximl Labs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pur Energy Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agnikul Cosmos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ePlane Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Company Name\n",
       "0  Guvi Geek Networks Private Limited\n",
       "1                         Maximl Labs\n",
       "2          Pur Energy Private Limited\n",
       "3                      Agnikul Cosmos\n",
       "4                  The ePlane Company"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The assignment consists of several company Names and they are taken into a csv file \n",
    "# The CSV file is then loaded into the program using pandas module\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "book = pd.read_csv('book.csv')\n",
    "\n",
    "book.head()\n",
    "\n",
    "book = book.drop(['S.no'], axis = 1)\n",
    "\n",
    "book.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_company = book['Company Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Guvi Geek Networks Private Limited\n",
       "1                              Maximl Labs\n",
       "2               Pur Energy Private Limited\n",
       "3                           Agnikul Cosmos\n",
       "4                       The ePlane Company\n",
       "5         PYTORQ Solutions Private Limited\n",
       "6                      Bigphi Technologies\n",
       "7             Ather Energy Private Limited\n",
       "8     Rekindle Automations Private Limited\n",
       "9     Aerostrovilos Energy Private Limited\n",
       "10                    Impensus Electronics\n",
       "11                           Doodhbhandaar\n",
       "12                                 Swapeco\n",
       "13         Statlogic India Private Limited\n",
       "14                     YNOS Venture Engine\n",
       "Name: Company Name, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Guvi Geek Networks Private Limited', 'Maximl Labs',\n",
       "       'Pur Energy Private Limited', 'Agnikul Cosmos',\n",
       "       'The ePlane Company', 'PYTORQ Solutions Private Limited',\n",
       "       'Bigphi Technologies', 'Ather Energy Private Limited',\n",
       "       'Rekindle Automations Private Limited',\n",
       "       'Aerostrovilos Energy Private Limited', 'Impensus Electronics',\n",
       "       'Doodhbhandaar', 'Swapeco', 'Statlogic India Private Limited',\n",
       "       'YNOS Venture Engine'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "list_np = np.array(list_company, dtype= list)\n",
    "\n",
    "list_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Data Frame into a array of type String\n",
    "\n",
    "list_np = list_np.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Guvi Geek Networks Private Limited', 'Maximl Labs',\n",
       "       'Pur Energy Private Limited', 'Agnikul Cosmos',\n",
       "       'The ePlane Company', 'PYTORQ Solutions Private Limited',\n",
       "       'Bigphi Technologies', 'Ather Energy Private Limited',\n",
       "       'Rekindle Automations Private Limited',\n",
       "       'Aerostrovilos Energy Private Limited', 'Impensus Electronics',\n",
       "       'Doodhbhandaar', 'Swapeco', 'Statlogic India Private Limited',\n",
       "       'YNOS Venture Engine'], dtype='<U36')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(list_np)\n",
    "\n",
    "# tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cosine Similarity \n",
    "\n",
    "\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# for   \n",
    "# cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# Importing Porter Stemmer from NLTK library to stem the sentences\n",
    "# importing re library to perform data preprocessing\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(list_np)):\n",
    "    print(i)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', list_np[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guvi geek network privat limit',\n",
       " 'maximl lab',\n",
       " 'pur energi privat limit',\n",
       " 'agnikul cosmo',\n",
       " 'eplan compani',\n",
       " 'pytorq solut privat limit',\n",
       " 'bigphi technolog',\n",
       " 'ather energi privat limit',\n",
       " 'rekindl autom privat limit',\n",
       " 'aerostrovilo energi privat limit',\n",
       " 'impensu electron',\n",
       " 'doodhbhandaar',\n",
       " 'swapeco',\n",
       " 'statlog india privat limit',\n",
       " 'yno ventur engin']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 28, 23, 21, 10],\n",
       " [29, 9],\n",
       " [7, 43, 21, 10],\n",
       " [32, 45],\n",
       " [13, 20],\n",
       " [49, 37, 21, 10],\n",
       " [9, 9],\n",
       " [9, 43, 21, 10],\n",
       " [24, 4, 21, 10],\n",
       " [35, 43, 21, 10],\n",
       " [32, 1],\n",
       " [4],\n",
       " [39],\n",
       " [5, 5, 21, 10],\n",
       " [23, 27, 31]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To convert the preprocessed words into a vector one_hot_encoding is performed on the data\n",
    "# To perform one hot encoding the modules are imported from keras library\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
    "onehot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0 20 28 23 21 10]\n",
      " [ 0  0  0  0  0  0  0  0 29  9]\n",
      " [ 0  0  0  0  0  0  7 43 21 10]\n",
      " [ 0  0  0  0  0  0  0  0 32 45]\n",
      " [ 0  0  0  0  0  0  0  0 13 20]\n",
      " [ 0  0  0  0  0  0 49 37 21 10]\n",
      " [ 0  0  0  0  0  0  0  0  9  9]\n",
      " [ 0  0  0  0  0  0  9 43 21 10]\n",
      " [ 0  0  0  0  0  0 24  4 21 10]\n",
      " [ 0  0  0  0  0  0 35 43 21 10]\n",
      " [ 0  0  0  0  0  0  0  0 32  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  4]\n",
      " [ 0  0  0  0  0  0  0  0  0 39]\n",
      " [ 0  0  0  0  0  0  5  5 21 10]\n",
      " [ 0  0  0  0  0  0  0 23 27 31]]\n"
     ]
    }
   ],
   "source": [
    "# Padding is perfomed as a part of data pre processing\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "sent_length=10\n",
    "embedded = pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The input string has also needs to go through data pre processing to convert into vectorized form\n",
    "\n",
    "name_onehot = [one_hot(name,voc_size)] \n",
    "name_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "name_pad = pad_sequences(name_onehot,padding='pre',maxlen=sent_length)\n",
    "print(name_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guvi Geek Networks Private Limited : 0.21063136593556733\n",
      "Maximl Labs : 0.2963992148724529\n",
      "Pur Energy Private Limited : 0.20248557974359568\n",
      "Agnikul Cosmos : 0.8149553245687551\n",
      "The ePlane Company : 0.838443616300637\n",
      "PYTORQ Solutions Private Limited : 0.15230388746165127\n",
      "Bigphi Technologies : 0.7071067811865476\n",
      "Ather Energy Private Limited : 0.20117019055664215\n",
      "Rekindle Automations Private Limited : 0.29708795551115325\n",
      "Aerostrovilos Energy Private Limited : 0.1663205257599714\n",
      "Impensus Electronics : 0.031234752377721213\n",
      "Doodhbhandaar : 1.0\n",
      "Swapeco : 1.0\n",
      "Statlogic India Private Limited : 0.4113450348948635\n",
      "YNOS Venture Engine : 0.6580865923618391\n"
     ]
    }
   ],
   "source": [
    "# The cosine similarity is performed on the data pre processed\n",
    "\n",
    "# The results are printed below\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "\n",
    "for x in range(0,len(embedded)):\n",
    "    print(list_np[x], ':',cosine_similarity(embedded[x].reshape(1, -1), name_pad.reshape(1, -1))[0][0])\n",
    "    \n",
    "# The obtained results are not satisfactory since the Cosine Similarity is 0.65 which is not the highest among the other results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['guvi geek network privat limit', 'maximl lab', 'pur energi privat limit', 'agnikul cosmo', 'eplan compani', 'pytorq solut privat limit', 'bigphi technolog', 'ather energi privat limit', 'rekindl autom privat limit', 'aerostrovilo energi privat limit', 'impensu electron', 'doodhbhandaar', 'swapeco', 'statlog india privat limit', 'yno ventur engin']\n",
      "maximl lab\n",
      "['maximl', 'lab']\n"
     ]
    }
   ],
   "source": [
    "# print(corpus)\n",
    "# print(corpus[1])\n",
    "# print(corpus[1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guvi \t 4\n",
      "geek \t 4\n",
      "network \t 6\n",
      "privat \t 5\n",
      "limit \t 4\n",
      "maximl \t 6\n",
      "lab \t 4\n",
      "pur \t 4\n",
      "energi \t 5\n",
      "privat \t 5\n",
      "limit \t 4\n",
      "agnikul \t 6\n",
      "cosmo \t 5\n",
      "eplan \t 5\n",
      "compani \t 7\n",
      "pytorq \t 5\n",
      "solut \t 4\n",
      "privat \t 5\n",
      "limit \t 4\n",
      "bigphi \t 6\n",
      "technolog \t 7\n",
      "ather \t 5\n",
      "energi \t 5\n",
      "privat \t 5\n",
      "limit \t 4\n",
      "rekindl \t 6\n",
      "autom \t 4\n",
      "privat \t 5\n",
      "limit \t 4\n",
      "aerostrovilo \t 10\n",
      "energi \t 5\n",
      "privat \t 5\n",
      "limit \t 4\n",
      "impensu \t 6\n",
      "electron \t 7\n",
      "doodhbhandaar \t 12\n",
      "swapeco \t 7\n",
      "statlog \t 6\n",
      "india \t 4\n",
      "privat \t 5\n",
      "limit \t 4\n",
      "yno \t 2\n",
      "ventur \t 5\n",
      "engin \t 4\n"
     ]
    }
   ],
   "source": [
    "# TO obtain neccessary results another approach is being taken \n",
    "# levenshtein distance is being taken as criteria to obtain the similarity between the words \n",
    "# the input word is compared with each word of each sentences.\n",
    "# The edit_distance alias levenshtein distance is being calculate and are shown below\n",
    "\n",
    "score = 100\n",
    "res = {}\n",
    "\n",
    "for x in range(0,len(corpus)):\n",
    "    for j in corpus[x].split():\n",
    "        print(j,'\\t',nltk.edit_distance(j,name))\n",
    "        distance = nltk.edit_distance(j,name)\n",
    "        if score > distance:\n",
    "            score = distance\n",
    "            res = {list_np[x]: distance}\n",
    "            final = list_np[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'YNOS Venture Engine': 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The least Score is taken as the neccesary result.\n",
    "\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YNOS Venture Engine'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Search results are: YNOS Venture Engine\n"
     ]
    }
   ],
   "source": [
    "print('The Search results are:',final )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
